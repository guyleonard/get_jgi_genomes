#!/usr/bin/env perl
use strict;
use warnings;

use Cwd;
use File::Basename;
use File::Path qw(make_path);
use Getopt::Std;
use List::MoreUtils qw(uniq);
use open qw(:std :utf8);
use utf8;
use XML::LibXML;

use Data::Dumper;

my $list    = "false";
my $cookies = 'cookies';
my ( $username, $password, $outdir, $project );

my %options = ();
getopts( 'u:p:c:g:fam:P:lh', \%options ) or display_help();

# Help
if ( $options{h} ) { display_help(); }

# Signin Options / Cookies
if ( defined $options{u} && defined $options{p} ) {
    $username = "$options{u}";
    $password = "$options{p}";
    signin( $username, $password );
}
elsif ( defined $options{c} ) {
    $cookies = $options{c};
    print "User supplied cookie, skipping signin process.\n";
}
else {
    display_help();
}

if ( $options{l} ) {
    $list = "true";
    print "\tOutput: List Only\n";
}

# Download Project XML & Output Dir
if ( defined $options{f} ) {
    $project = 'fungi';

    print "Downloading XML from JGI -cosm Project: Mycocosm aka $project\n";
    download_xml($project);

    print "Parsing XML\n";
    parse_cosm_xml( $project, $list );
}
elsif ( defined $options{a} ) {
    $project = 'algae';

    print "Downloading XML from JGI -cosm Project: Phycocosm aka $project\n";
    download_xml($project);

    print "Parsing XML\n";
    parse_cosm_xml( $project, $list );
}
elsif ( defined $options{P} ) {
    $project = 'PhytozomeV' . "$options{P}";

    print "Downloading XML from JGI -zome Project: $project\n";
    download_xml($project);

    print "Parsing XML\n";
    parse_phytozome_xml( $project, $list );
}
elsif ( defined $options{m} ) {
    $project = 'MetazomeV' . "$options{m}";

    print "Downloading XML from JGI -zome Project: $project\n";
    download_xml($project);

    print "Parsing XML\n";
    parse_phytozome_xml( $project, $list );
}
else {
    print "No Output Directory or Group Project ID\n";
    exit(1);
}

sub display_help {
    print "Usage:\n";
    print
        "  get_jgi_genomes [-u <username> -p <password>] | [-c <cookies>] [-f | -a | -P 12 | -m 3] (-l)\n\n";
    print "Required:\n";
    print "\t-u <username>\n";
    print "\t-p <password>\n";
    print "or\n";
    print "\t-c <cookie file>\n";
    print "Options:\n";
    print "\t-f Mycocosm aka fungi\n";
    print "\t-a Phycocosm aka algae\n";
    print "\t-P <version> PhytozomeV\n";
    print "\t-m <metazome> MetazomeV\n";
    print "Listing:";
    print "\t-l list only, no downloads\n";

    exit(1);
}

# JGI insist we log in, that's okay. You should be aware that different genome portals
# may have different licenses etc...it's up to the individual user to be aware of these.
# So, let's login to the DOE JGI SSO
# We can do this with curl and our username/password
# This saves a cookie file for use later, it will need refreshing.
sub signin {

    my $user = shift;
    my $pass = shift;

    if ( -e 'cookies' ) {
        if ( -A 'cookies' > 1 ) {
            print "Logging In Again...\n";
            run_cmd(
                #"curl --silent 'https://signon-old.jgi.doe.gov/signon/create' --data-urlencode 'login=$user' --data-urlencode 'password=$pass' -c cookies > /dev/null"
                "curl --silent 'https://signon.jgi.doe.gov/signon/create' --data-urlencode 'login=$user' --data-urlencode 'password=$pass' -c cookies > /dev/null"
            );
            print "Successfully Logged In!\n";
        }
        else {
            print "Already logged in...\n";
        }
    }
    else {
        print "Logging In...\n";
        run_cmd(
                #"curl --silent 'https://signon-old.jgi.doe.gov/signon/create' --data-urlencode 'login=$user' --data-urlencode 'password=$pass' -c cookies > /dev/null"
                "curl --silent 'https://signon.jgi.doe.gov/signon/create' --data-urlencode 'login=$user' --data-urlencode 'password=$pass' -c cookies > /dev/null"
        );
        print "Successfully Logged In!\n";
    }
}

# Now let's use curl again with our cookie signon and scrape the XML
# Only refresh if the file is older than 10 days...You can change this as you like
sub download_xml {
    my $portal = shift;

    if ( !-e "$portal\_files.xml" ) {    #> 10 ) {

        # Get portal List
        print "Downloading $portal XML - This may take some time...\n";
        run_cmd(
            "curl 'https://genome.jgi.doe.gov/portal/ext-api/downloads/get-directory?organism=$portal' -b $cookies > $portal\_files.xml"
        );
    }
    else {
        print
            "\t$portal\_files.xml is not older than 10 days, skipping re-download.\n";
    }

    # I can't get the XML parsing to work when "&quot;" exists in the file
    # let's cheat and remove it with sed?
    run_cmd("sed -i \'s/&quot;//g\' $portal\_files.xml");
}

sub parse_phytozome_xml {

    my ( $portal, $list ) = @_;

    my $xml_file = "$portal\_files.xml";

    my $portal_xml
        = XML::LibXML->load_xml( location => $xml_file, no_blanks => 1 );

    my $query = '//folder[@name="annotation"]';

    my %results;

    my $search = 'protein';
    if ( $portal =~ m/metazome/i ) { $search = 'peptide' }

    for my $file ( $portal_xml->findnodes($query) ) {
        for my $file_props ( $file->findnodes('//file') ) {

            my $url = $file_props->getAttribute('url');
            my $label = ( split /\//, $url )[9];
            if ( $url =~ m/.*$search\.fa\.gz/ ) {
                $results{"$label"} = "$url";
            }
        }
    }

    if ( !-d $portal ) {
        make_path($portal);
    }

    if ( $list eq "true" ) {

        genome_list_phytozome( \%results, $portal );
    }

    else {
        download_files_phytozome( \%results, $portal );
    }
}

## Parse the XML DOM
sub parse_cosm_xml {

    my ( $portal, $list ) = @_;

    my $xml_file = "$portal\_files.xml";

    my $portal_xml
        = XML::LibXML->load_xml( location => $xml_file, no_blanks => 1 );

    my $query
        = '/organismDownloads[@name="'
        . $portal
        . '"]/folder[@name="Files"]/folder[@name="Annotation"]/folder[@name="Filtered Models (best)"]/folder[@name="Proteins"]';

    my %results;

    for my $file ( $portal_xml->findnodes($query) ) {
        for my $file_props ( $file->findnodes('./*') ) {

            my $label = $file_props->getAttribute('label');
            my $url   = $file_props->getAttribute('url');

            # if the files don't look like this, then we don't want them
            # Armlut1_GeneCatalog_proteins_20180531.aa.fasta.gz
            # *proteins.fasta.gz
            # we also remove any files with some modifiers
            # then push them to a hash to remove genomes with two sets
            # of proteins.
            # it's a bit of a fudge, but the xml makes no effort to define
            # the set of AAs that are representative of the genome

            if ( $url =~ m/.*\_GeneCatalog_proteins_\d+\.aa\.fasta.gz/ ) {
                if ( $url !~ m/primary|secondary|alleles|diploid|old/ ) {
                    $results{"$label"} = "$url";
                }
            }
            elsif ( $url =~ m/.*proteins\.fasta\.gz/ ) {
                $results{"$label"} = "$url";
            }
        }
    }

    if ( !-d $portal ) {
        make_path($portal);
    }

    if ( $list eq "true" ) {

        genome_list( \%results, $portal );
    }

    else {
        download_files_cosms( \%results, $portal );
    }
}

sub genome_list {
    my %list_of_urls = %{ $_[0] };
    my $portal       = $_[1];

    my $filename = "$portal\/$portal\_list.txt";
    open my $fileout, '>>', $filename;

    foreach ( sort keys %list_of_urls ) {
        my $taxa   = $_;
        my $url    = $list_of_urls{$_};
        my @jgi_id = split /\//, $url;

        print $fileout
            "$taxa\t$jgi_id[2]\thttps://genome.jgi.doe.gov/portal/$jgi_id[2]/download/$jgi_id[4]\n";
    }

    close($fileout);
}

sub download_files_cosms {
    my %list_of_urls = %{ $_[0] };
    my $portal       = $_[1];

    foreach ( sort keys %list_of_urls ) {
        my $taxa     = $_;
        my $url      = $list_of_urls{$_};
        my $filename = ( split /\//, $url )[4];

        print "\tRetrieving: $filename\n";

        run_cmd(
            "curl --silent 'https://genome.jgi.doe.gov$url' -b cookies > $portal\/$filename"
        );
    }
}

sub genome_list_phytozome {
    my %list_of_urls = %{ $_[0] };
    my $portal       = $_[1];

    my $filename = "$portal\/$portal\_list.txt";
    open my $fileout, '>>', $filename;

    foreach ( sort keys %list_of_urls ) {
        my $taxa = $_;
        my $url  = $list_of_urls{$_};

        print $fileout "$taxa\thttps://genome.jgi.doe.gov$url\n";
    }

    close($fileout);
}

sub download_files_phytozome {
    my %list_of_urls = %{ $_[0] };
    my $portal       = $_[1];

    foreach ( sort keys %list_of_urls ) {
        my $taxa     = $_;
        my $url      = $list_of_urls{$_};
        my $filename = ( split /\//, $url )[9];

        print "\tRetrieving: $filename\n";

        run_cmd(
            "curl --silent 'https://genome.jgi.doe.gov$url' -b cookies > $portal\/$filename"
        );
    }
}

sub run_cmd {
    my ( $cmd, $quiet ) = @_;
    msg("Running: $cmd") unless $quiet;
    system($cmd) == 0 or error("Error $? running command");
}

sub error {
    msg(@_);
    exit(1);
}

sub msg {
    print STDERR "@_\n";
}
